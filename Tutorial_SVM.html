<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="true" />
<meta name="allow-skip" content="true" />

<title>Support Vector Machines in R</title>


<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>

<!-- taken from https://github.com/rstudio/rmarkdown/blob/67b7f5fc779e4cfdfd0f021d3d7745b6b6e17149/inst/rmd/h/default.html#L296-L362 -->
<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>
<!-- end tabsets -->



</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<style>
div {
  text-align: justify;
}
/***********************/
/*Títulos ## y autoría F6EACD*/
/***********************/
h1, h2 {
  color: #6D4101;
  padding: .4em; /*es decir el 60 por ciento del tamaño de la letra*/
  font-family: "Courier New", monospace;
  font-size: 35px;
  font-weight: bold;
  opacity: 0.95;
}
em {
  color: #8A6C0C;
  font-family: "Courier New", monospace;
  font-size: 18px;
  padding: .2em;
  opacity: 0.97;
  font-weight: bold;
}
/***********************/
/* Cuerpo */
/***********************/
body {
  font-family: Verdana, Helvetica, sans-serif;
  font-size: 16;
  background-color: #EEF5F9;
  color: #000000;
}
/***********************/
/* Títulos con ###     */
/***********************/
h3, h4, h5{
  color: #06116C;
  font-family: Verdana, Helvetica, sans-serif;
}
/*******************************************/
/* Referencias a páginas o a otro documento*/
/*******************************************/
a {
    color: #B8870F;
    text-decoration: none;
}
/**********************/
/* Chunks de exercises*/
/**********************/
.ace-tm {
    background-color: #FFFEF7;
    color: #010730;
}
/***********************/
/* tabla de contenidos */
/***********************/
.topicsList {
  padding: .5em;
}
.topicsHeader {
  color: #06116C;
  padding: .5em;
}
.topicsList #doc-metadata {
  color: #06116C;
  padding: .5em;
}
.topicsList .topic.current {
  background-color: #8A6C0C;
  color: #FFFFFF;
  font-weight: bold;
}
.topicsList .topic:hover, .topicsList .topic:active {
  background-color: #E0CD4E;
  color: #01053D;
}
/***********/
/* Botones */
/***********/
.btn {
  background-color: #000857;
  color: #EBEDFF;
}
/* cambiar de página */
.btn-default {
    color: #EBEDFF;
    background-color: #000857;
    border: none;
}
/* cambiar de página */
.btn-light {
  background-color: #000857;
  color: #EBEDFF;
}
/* run code */
.btn-primary , .btn-success, .btn-info{
  background-color: #786300;
  color: #EBEDFF;
}
/* mientras está desabilitados */
.btn:hover, .btn:active, .btn:disabled {
  background-color: #786300;
  color: #EBEDFF;
}
/**********/
/* Código */
/**********/
code {
    color: #6D4101;
    background-color:  #F7FBF9;
    font-size: 15px;
    font-weight: bold;
}
/**************************/
/* Recuadro para ejemplos */
/**************************/
.boxed {
    background: #F7FBF9;
    color: black;
    border: 3px solid #C83737;
    margin: 0px auto;
    width: 456px;
    padding: 10px;
    border-radius: 10px;
  }
.note {
    padding: 1em;
    margin: 1em 0;
    padding-left: 100px;
    background-size: 70px;
    background-repeat: no-repeat;
    background-position: 15px 15px;
    min-height: 120px;
    color: black;
    background-color: lightgrey;
    border: solid 5px #C83737;
    background-image: url("manzana.png");
  }
.note_white {
    padding: 1em;
    margin: 1em 0;
    padding-left: 100px;
    background-size: 70px;
    background-repeat: no-repeat;
    background-position: 15px 15px;
    min-height: 120px;
    color: black;
    background-color: #F7FBF9;
    border: solid 5px #C83737;
    background-image: url("manzana.png");
  }
</style>
<div id="section-introducción" class="section level2">
<h2>Introducción</h2>
<p>El tutorial usará un dataset para ejemplificar el uso de los diferentes kernels (famosos) y utilidad de esta función. Si quieres conocer algunas ideas teóricas de esta técnica <em>SVM</em>, constulta este <a href="https://maquinas-de-soporte-vectorial.netlify.app/">breve artículo</a>.</p>
<div id="section-objetivo" class="section level3">
<h3>Objetivo</h3>
<p>Que aprendas las bases sobre la función <code>svm()</code> de la librería <code>e1071</code>. Esta función permite implementar la técnica de clásificación <em>Support Vector Machines</em> en datasets.</p>
</div>
<div id="section-cargar-librería" class="section level3">
<h3>Cargar librería</h3>
<p>Para poder hacer uso de la función <code>svm()</code>, es primordial cargar la librería <code>e1071</code>, puedes hacerlo en el siguiente espacio de código.</p>
<div class="tutorial-exercise" data-label="ej1" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>#
library(____)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-parámetros-de-svm" class="section level3">
<h3>Parámetros de svm()</h3>
<ul>
<li><p><code>formula</code>: respuesta ~ explicativas</p></li>
<li><p><code>data</code>: data.frame</p></li>
<li><p><code>scale</code>: ¿Se escalan los datos? Verdadero (T) o Falso (F)</p></li>
<li><p><code>type</code>: “C-classification” por defecto.</p></li>
<li><p><code>kernel</code>: tipo de kernel</p>
<ul>
<li><p>“linear”: <span class="math inline">\(K(x_i, x_j) =\displaystyle \sum_{l = 1}^p x_{il}x_{jl}\)</span></p></li>
<li><p>“polynomial”: <span class="math inline">\(K(x_i, x_j) = \bigg( 1 + \displaystyle \sum_{l = 1}^p x_{il}x_{jl}\bigg)^d\)</span></p></li>
<li><p>“radial”: <span class="math inline">\(K(x_i, x_j) = \exp \bigg\{ -\gamma \displaystyle \sum_{l = 1}^p (x_{il} - x_{jl})^2\bigg\}\)</span></p></li>
</ul></li>
<li><p><code>cost</code>: 1, por defecto. Es la <span class="math inline">\(C\)</span> del problema de optimización.</p></li>
</ul>
<p>Ve más sobre la función en la <a href="https://www.rdocumentation.org/packages/e1071/versions/1.7-8">documentación de R</a></p>
</div>
</div>
<div id="section-confirmando-estereotipos" class="section level2">
<h2>¿Confirmando estereotipos?</h2>
<p>En esta sección consideremos el dataset siguiente:</p>
<div id="section-forma-de-los-datos" class="section level3">
<h3>Forma de los datos</h3>
<ul>
<li><p><strong>speed_gender_height</strong>: Velocidad, género y altura de 1325 estudiantes.</p>
<p>Son 1302 observaciones, la variable respuesta tiene las etiquetas “female” y “male” de la variable categórica <span class="math inline">\(y =\)</span> gender.</p>
<p>Las variables explicativas son “height” y “speed” de las personas participantes en el estudio.</p></li>
</ul>
<div>
<p style="text-align:center;">
<img src="https://okdiario.com/img/2018/01/19/-por-que-los-hombres-pueden-correr-mas-rapido-que-las-mujeres-2.jpg" width="350" />
</p>
</div>
<p>En el siguiente código puedes explorar de forma visual la forma en que se acomodan las observaciones en el data set popcorn.</p>
<div class="tutorial-exercise" data-label="pl1" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>plot_info &lt;- ggplot(info, aes(x = speed, y = height, color = gender)) + 
  geom_point(alpha = ___) + 
  ggtitle(&quot;Personal Information&quot;) + 
  theme_minimal() + 
  scale_color_manual(values = c(&quot;#BD9B17&quot;, &quot;#1A1458&quot;))

plot_info</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
</div>
<div id="section-separar-datos" class="section level2">
<h2>Separar datos</h2>
<p>Para poder comprobar la utilidad de nuestro modelo, es común hacer que el conjuntos de datos se parta en dos (inicialmente…):</p>
<ul>
<li><p><strong>trainingset</strong> para construir el modelo) y</p></li>
<li><p><strong>testset</strong> para hacer las predicciones y poner a prueba el poder de predicción del modelo.</p></li>
</ul>
<p>En este ejercicio usaremos el dataset info para partir los datos en dos conjuntos.</p>
<div class="tutorial-exercise" data-label="ej2" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># 80% para construir el modelo, 20% para &quot;probar su capacidad de predecir&quot;
info[, &quot;train&quot;] &lt;- ifelse(runif(nrow(info)) &lt; .8, 1, 0)
trainset &lt;- info[info$train == 1, ]
testset &lt;- info[info$train == 0, ]

trainColNum &lt;- grep(&quot;train&quot;, names(info))
trainset &lt;- trainset[, -trainColNum]
testset &lt;- testset[, -trainColNum]</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-crear-modelo" class="section level2">
<h2>Crear modelo</h2>
<p>Para implementar la técnica SVM con los diferentes kernels, presentamos los siguientes ejercicios:</p>
<div id="section-lineal" class="section level3">
<h3>Lineal</h3>
<p><span class="math display">\[K(x_i, x_j) =\displaystyle \sum_{l = 1}^p x_{il}x_{jl}\]</span> Ajusta un SVM con un kernel lineal a los datos <code>info</code></p>
<div class="tutorial-exercise" data-label="ej3" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>svm_model_l &lt;- svm(gender ~ ., 
                data = trainset, 
                type = &quot;C-classification&quot;, 
                kernel = &quot;____&quot;, 
                scale = FALSE)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Revisemos algunos elementos que nos devuelve el modelo</p>
<div class="tutorial-exercise" data-label="ej4" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>names(svm_model_l) # ¿Qué nos devuelve el modelo?
svm_model_l$index # ¿Cuáles observaciones son vectores soporte?
svm_model_l$rho # Beta0 (intercepto)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Obtengamos la pendiente y ordenada al origen del hiperplano (recta, para las amistades :satisfied:)</p>
<div class="tutorial-exercise" data-label="ej5" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># Vector de pesos
w &lt;- t(svm_model_l$coefs) %*% svm_model_l$SV
#Pendiente
slope_l &lt;- -w[1]/w[2]
#Ordenada al origen
intercerpt_l &lt;- svm_model_l$rho / w[2]</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Hagamos un gráfico de los datos con el hiperplano y los márgenes</p>
<div class="tutorial-exercise" data-label="ej6" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>plot_info_svm_l &lt;-  plot_info + 
  # resaltamos los vectores soporte
  geom_point(data = trainset[svm_model_l$____,],
             aes(x = speed, y = height),
             color = &quot;#6EA815&quot;, size = 2, alpha = .3) +
  # añadimos el hiperplano
  geom_abline(slope = slope_l,
              intercept = ______,
              size = 1,
              color = &quot;#A91323&quot;) + 
  # con sus lineas paralelas con el margen correspondiente
  geom_abline(slope = slope_l, 
              intercept = intercerpt_l - 1/w[2],
              linetype = &quot;dashed&quot;,
              color = &quot;#A91323&quot;) +
  geom_abline(slope = slope_l, 
              intercept = intercerpt_l + 1/w[2],
              linetype = &quot;dashed&quot;,
              color = &quot;#A91323&quot;)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>¿Qué tan bien hizo la clasificación?</p>
<div class="tutorial-exercise" data-label="ejextr" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>pred_test_1 &lt;- predict(svm_model_l, testset)
mean(pred_test_1 == testset$gender) #accuracy</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-polinomial" class="section level3">
<h3>Polinomial</h3>
<p><span class="math display">\[K(x_i, x_j) = \bigg( 1 + \displaystyle \sum_{l = 1}^p x_{il}x_{jl}\bigg)^d\]</span> Recordemos que existen diversos hiperparámetros, parámetros que nosotros decidimos. Para no hacer una elección al azar, la función <code>tune.svm()</code> nos permite elegir “los mejores” de entre la lista que demos.</p>
<p>Esto lo hace buscando el modelo que mejores aciertos tenga de predicción, o menor error, de entre todas las combinaciones posibles.</p>
<div class="tutorial-exercise" data-label="ej7" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>tune_out_p &lt;- 
  tune.svm(
    #en vez del data set, y la fórmula, se escriben la respuesta y
    #las variables explicativas
    x = trainset[, -2], y = trainset[, 2],
    type = &quot;C-classification&quot;,
    kernel = &quot;_____&quot;, degree = 2,
    #Damos diferentes valores para los parámetros
    cost = 10^(-1:1),
    gamma = c(0.1, 1)
    )

#Obtenemos los &quot;mejores&quot; valores de hiperaprámetros
c &lt;- tune_out_p$best.parameters$cost
gma &lt;- tune_out_p$best.parameters$gamma</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Una vez hecho lo anterior, podemos construir nuestro modelo</p>
<div class="tutorial-exercise" data-label="ej8" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>svm_model_p &lt;- svm(gender ~ ., 
                data = ____, 
                type = &quot;C-classification&quot;, 
                kernel = &quot;polynomial&quot;, degree = ___,
                cost = c,
                gamma = gma)

# ¿Cuántas de las observaciones son vectores soporte?
length(svm_model_p$index) </code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<p>Por último veamos la exactitud de predicción del modelo (accuracy) así como el plot que nos brinda <code>e1071</code> por defecto.</p>
<div class="tutorial-exercise" data-label="ej9" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>pred_test_p &lt;- predict(svm_model_p, testset)
mean(pred_test_p == testset$gender) #accuracy

svm_p_plot &lt;- plot(svm_model_p, trainset)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-radial" class="section level3">
<h3>Radial</h3>
<p><span class="math display">\[K(x_i, x_j) = \exp \bigg\{ -\gamma \displaystyle \sum_{l = 1}^p (x_{il} - x_{jl})^2\bigg\}\]</span> Como en el ejerciicio anterior, he buscado los “mejores” hiperparámetros. Ahora solo te toca obtener el modelo, ver su exactitud de predicción y graficar.</p>
<p>Considera que en este ejercicio el objetivo es que uses un kernel radial.</p>
<div class="tutorial-exercise" data-label="ej10" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>svm_model_r &lt;- svm(____ ~ ., 
                data = trainset, 
                type = &quot;C-classification&quot;, 
                kernel = &quot;____&quot;,
                cost = tune_out_r$best.parameters$___,
                gamma = tune_out_r$____$gamma)

summary(____) 

pred_test_r &lt;- predict(svm_model_r, ____)
mean(_____ == testset$gender) #accuracy

plot(svm_model_r, _____)</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div class="tutorial-exercise-support" data-label="ej10-solution" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>svm_model_r &lt;- svm(gender ~ ., 
                data = trainset, 
                type = &quot;C-classification&quot;, 
                kernel = &quot;radial&quot;,
                cost = tune_out_r$best.parameters$cost,
                gamma = tune_out_r$best.parameters$gamma)

summary(svm_model_r) 

pred_test_r &lt;- predict(svm_model_r, testset)
mean(pred_test_r == testset$gender) #accuracy

plot(svm_model_r, trainset)</code></pre>
</div>
</div>
</div>
<div id="section-qué-modelo-es-mejor" class="section level2">
<h2>¿Qué modelo es mejor?</h2>
<p>Como sabemos, la respuesta no existe a una pregunta que carece de sentido. El problema es que bajo diferentes datasets, los modelos pueden variar en la exactitud de su clasificación.</p>
<p>Lo que es cierto es que para este dataset en particular obtuvimos:</p>
<div id="section-lineal-82.29-accuracy" class="section level3">
<h3>Lineal 82.29% accuracy</h3>
<div>
<p style="text-align:center;">
<img src="images/svm_tut1.png" width="650" />
</p>
</div>
</div>
<div id="section-polinomial-66.66-accuracy" class="section level3">
<h3>Polinomial 66.66% accuracy</h3>
<div>
<p style="text-align:center;">
<img src="images/svm_tut2.png" width="650" />
</p>
</div>
</div>
<div id="section-radial-81.94-accuracy" class="section level3">
<h3>Radial 81.94% accuracy</h3>
<div>
<p style="text-align:center;">
<img src="images/svm_tut3.png" width="650" />
</p>
</div>
<p>Debemos considerar que los modelos estuvieron sujetos tanto a la partición que se hizo para crear el modelo (trainset/testset), como a los hiperparámetros que <strong>nosotros</strong> enlistados.</p>
<div>
<p style="text-align:center;">
<img src="https://thumbs.gfycat.com/SevereAlertBunting-size_restricted.gif" width="750" />
</p>
</div>

<script type="application/shiny-prerendered" data-context="server-start">
#Librerías a usar

  #Hacer el tutorial
  library(learnr)
  #Hacer los modelos de SVM
  library(e1071)
  #Hacer gráficas bonitas y acomodadas
  library(ggplot2)
  library(gridExtra)
  #Leer los archivos csv
  library(readxl)
  #Manejar los archivos
  library(dplyr)

#Modificaciónes para los chunks
knitr::opts_chunk$set(echo = FALSE, fig.align ='center')

</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::clear_exercise_cache_env()
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::i18n_observe_tutorial_language(input, session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::event_trigger(session, "session_stop")
      })
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_setup_chunk("__setup__", c("#Librerías a usar", "", "  #Hacer el tutorial", "  library(learnr)", 
"  #Hacer los modelos de SVM", "  library(e1071)", "  #Hacer gráficas bonitas y acomodadas", 
"  library(ggplot2)", "  library(gridExtra)", "  #Leer los archivos csv", 
"  library(readxl)", "  #Manejar los archivos", "  library(dplyr)", 
"", "#Modificaciónes para los chunks", "knitr::opts_chunk$set(echo = FALSE, fig.align ='center')", 
""), overwrite = FALSE)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_setup_chunk("__setup__", c("#Librerías a usar", "", "  #Hacer el tutorial", "  library(learnr)", 
"  #Hacer los modelos de SVM", "  library(e1071)", "  #Hacer gráficas bonitas y acomodadas", 
"  library(ggplot2)", "  library(gridExtra)", "  #Leer los archivos csv", 
"  library(readxl)", "  #Manejar los archivos", "  library(dplyr)", 
"", "#Modificaciónes para los chunks", "knitr::opts_chunk$set(echo = FALSE, fig.align ='center')", 
""), overwrite = FALSE)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ej1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ej1-code-editor`)), session)
output$`tutorial-exercise-ej1-output` <- renderUI({
  `tutorial-exercise-ej1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ej1", list(setup = NULL, chunks = list(list(label = "ej1", code = "#\nlibrary(____)", 
    opts = list(label = "\"ej1\"", exercise = "TRUE"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    options = list(eval = FALSE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, strip.white = TRUE, 
        size = "normalsize", background = "#F7F7F7", cache = 0, 
        cache.path = "Tutorial_SVM_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ej1", exercise = TRUE, 
        code = c("#", "library(____)"), out.width.px = 624, out.height.px = 384, 
        params.src = "ej1, exercise=TRUE", fig.num = 0, exercise.df_print = "paged", 
        exercise.checker = "NULL"), engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-pl1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-pl1-code-editor`)), session)
output$`tutorial-exercise-pl1-output` <- renderUI({
  `tutorial-exercise-pl1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("pl1", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "pl1", code = "plot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + \n  geom_point(alpha = ___) + \n  ggtitle(\"Personal Information\") + \n  theme_minimal() + \n  scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\nplot_info", 
        opts = list(label = "\"pl1\"", exercise = "TRUE", exercise.setup = "\"datas\""), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, options = list(eval = FALSE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        strip.white = TRUE, size = "normalsize", background = "#F7F7F7", 
        cache = 0, cache.path = "Tutorial_SVM_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "pl1", exercise = TRUE, 
        exercise.setup = "datas", code = c("plot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + ", 
        "  geom_point(alpha = ___) + ", "  ggtitle(\"Personal Information\") + ", 
        "  theme_minimal() + ", "  scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))", 
        "", "plot_info"), out.width.px = 624, out.height.px = 384, 
        params.src = "pl1, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ej2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ej2-code-editor`)), session)
output$`tutorial-exercise-ej2-output` <- renderUI({
  `tutorial-exercise-ej2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ej2", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "ej2", code = "# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]", 
        opts = list(label = "\"ej2\"", exercise = "TRUE", exercise.setup = "\"datas\""), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, options = list(eval = FALSE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        strip.white = TRUE, size = "normalsize", background = "#F7F7F7", 
        cache = 0, cache.path = "Tutorial_SVM_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ej2", exercise = TRUE, 
        exercise.setup = "datas", code = c("# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"", 
        "info[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)", 
        "trainset <- info[info$train == 1, ]", "testset <- info[info$train == 0, ]", 
        "", "trainColNum <- grep(\"train\", names(info))", "trainset <- trainset[, -trainColNum]", 
        "testset <- testset[, -trainColNum]"), out.width.px = 624, 
        out.height.px = 384, params.src = "ej2, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ej3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ej3-code-editor`)), session)
output$`tutorial-exercise-ej3-output` <- renderUI({
  `tutorial-exercise-ej3-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ej3", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "ej3", code = "svm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"____\", \n                scale = FALSE)", 
        opts = list(label = "\"ej3\"", exercise = "TRUE", exercise.setup = "\"datas\""), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, options = list(eval = FALSE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        strip.white = TRUE, size = "normalsize", background = "#F7F7F7", 
        cache = 0, cache.path = "Tutorial_SVM_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ej3", exercise = TRUE, 
        exercise.setup = "datas", code = c("svm_model_l <- svm(gender ~ ., ", 
        "                data = trainset, ", "                type = \"C-classification\", ", 
        "                kernel = \"____\", ", "                scale = FALSE)"
        ), out.width.px = 624, out.height.px = 384, params.src = "ej3, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ej4-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ej4-code-editor`)), session)
output$`tutorial-exercise-ej4-output` <- renderUI({
  `tutorial-exercise-ej4-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ej4", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "ej4", code = "names(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)", 
        opts = list(label = "\"ej4\"", exercise = "TRUE", exercise.setup = "\"datas\""), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, options = list(eval = FALSE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        strip.white = TRUE, size = "normalsize", background = "#F7F7F7", 
        cache = 0, cache.path = "Tutorial_SVM_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ej4", exercise = TRUE, 
        exercise.setup = "datas", code = c("names(svm_model_l) # ¿Qué nos devuelve el modelo?", 
        "svm_model_l$index # ¿Cuáles observaciones son vectores soporte?", 
        "svm_model_l$rho # Beta0 (intercepto)"), out.width.px = 624, 
        out.height.px = 384, params.src = "ej4, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ej5-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ej5-code-editor`)), session)
output$`tutorial-exercise-ej5-output` <- renderUI({
  `tutorial-exercise-ej5-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ej5", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "ej5", code = "# Vector de pesos\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\n#Pendiente\nslope_l <- -w[1]/w[2]\n#Ordenada al origen\nintercerpt_l <- svm_model_l$rho / w[2]", 
        opts = list(label = "\"ej5\"", exercise = "TRUE", exercise.setup = "\"datas\""), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, options = list(eval = FALSE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        strip.white = TRUE, size = "normalsize", background = "#F7F7F7", 
        cache = 0, cache.path = "Tutorial_SVM_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ej5", exercise = TRUE, 
        exercise.setup = "datas", code = c("# Vector de pesos", 
        "w <- t(svm_model_l$coefs) %*% svm_model_l$SV", "#Pendiente", 
        "slope_l <- -w[1]/w[2]", "#Ordenada al origen", "intercerpt_l <- svm_model_l$rho / w[2]"
        ), out.width.px = 624, out.height.px = 384, params.src = "ej5, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ej6-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ej6-code-editor`)), session)
output$`tutorial-exercise-ej6-output` <- renderUI({
  `tutorial-exercise-ej6-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ej6", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "ej6", code = "plot_info_svm_l <-  plot_info + \n  # resaltamos los vectores soporte\n  geom_point(data = trainset[svm_model_l$____,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  # añadimos el hiperplano\n  geom_abline(slope = slope_l,\n              intercept = ______,\n              size = 1,\n              color = \"#A91323\") + \n  # con sus lineas paralelas con el margen correspondiente\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")", 
        opts = list(label = "\"ej6\"", exercise = "TRUE", exercise.setup = "\"datas\""), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, options = list(eval = FALSE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        strip.white = TRUE, size = "normalsize", background = "#F7F7F7", 
        cache = 0, cache.path = "Tutorial_SVM_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ej6", exercise = TRUE, 
        exercise.setup = "datas", code = c("plot_info_svm_l <-  plot_info + ", 
        "  # resaltamos los vectores soporte", "  geom_point(data = trainset[svm_model_l$____,],", 
        "             aes(x = speed, y = height),", "             color = \"#6EA815\", size = 2, alpha = .3) +", 
        "  # añadimos el hiperplano", "  geom_abline(slope = slope_l,", 
        "              intercept = ______,", "              size = 1,", 
        "              color = \"#A91323\") + ", "  # con sus lineas paralelas con el margen correspondiente", 
        "  geom_abline(slope = slope_l, ", "              intercept = intercerpt_l - 1/w[2],", 
        "              linetype = \"dashed\",", "              color = \"#A91323\") +", 
        "  geom_abline(slope = slope_l, ", "              intercept = intercerpt_l + 1/w[2],", 
        "              linetype = \"dashed\",", "              color = \"#A91323\")"
        ), out.width.px = 624, out.height.px = 384, params.src = "ej6, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ejextr-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ejextr-code-editor`)), session)
output$`tutorial-exercise-ejextr-output` <- renderUI({
  `tutorial-exercise-ejextr-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ejextr", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "ejextr", code = "pred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy", 
        opts = list(label = "\"ejextr\"", exercise = "TRUE", 
            exercise.setup = "\"datas\""), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, strip.white = TRUE, size = "normalsize", 
        background = "#F7F7F7", cache = 0, cache.path = "Tutorial_SVM_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ejextr", 
        exercise = TRUE, exercise.setup = "datas", code = c("pred_test_1 <- predict(svm_model_l, testset)", 
        "mean(pred_test_1 == testset$gender) #accuracy"), out.width.px = 624, 
        out.height.px = 384, params.src = "ejextr, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ej7-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ej7-code-editor`)), session)
output$`tutorial-exercise-ej7-output` <- renderUI({
  `tutorial-exercise-ej7-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ej7", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "ej7", code = "tune_out_p <- \n  tune.svm(\n    #en vez del data set, y la fórmula, se escriben la respuesta y\n    #las variables explicativas\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"_____\", degree = 2,\n    #Damos diferentes valores para los parámetros\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\n\n#Obtenemos los \"mejores\" valores de hiperaprámetros\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma", 
        opts = list(label = "\"ej7\"", exercise = "TRUE", exercise.setup = "\"datas\""), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, options = list(eval = FALSE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        strip.white = TRUE, size = "normalsize", background = "#F7F7F7", 
        cache = 0, cache.path = "Tutorial_SVM_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ej7", exercise = TRUE, 
        exercise.setup = "datas", code = c("tune_out_p <- ", 
        "  tune.svm(", "    #en vez del data set, y la fórmula, se escriben la respuesta y", 
        "    #las variables explicativas", "    x = trainset[, -2], y = trainset[, 2],", 
        "    type = \"C-classification\",", "    kernel = \"_____\", degree = 2,", 
        "    #Damos diferentes valores para los parámetros", 
        "    cost = 10^(-1:1),", "    gamma = c(0.1, 1)", "    )", 
        "", "#Obtenemos los \"mejores\" valores de hiperaprámetros", 
        "c <- tune_out_p$best.parameters$cost", "gma <- tune_out_p$best.parameters$gamma"
        ), out.width.px = 624, out.height.px = 384, params.src = "ej7, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ej8-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ej8-code-editor`)), session)
output$`tutorial-exercise-ej8-output` <- renderUI({
  `tutorial-exercise-ej8-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ej8", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "ej8", code = "svm_model_p <- svm(gender ~ ., \n                data = ____, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = ___,\n                cost = c,\n                gamma = gma)\n\n# ¿Cuántas de las observaciones son vectores soporte?\nlength(svm_model_p$index) ", 
        opts = list(label = "\"ej8\"", exercise = "TRUE", exercise.setup = "\"datas\""), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, options = list(eval = FALSE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        strip.white = TRUE, size = "normalsize", background = "#F7F7F7", 
        cache = 0, cache.path = "Tutorial_SVM_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ej8", exercise = TRUE, 
        exercise.setup = "datas", code = c("svm_model_p <- svm(gender ~ ., ", 
        "                data = ____, ", "                type = \"C-classification\", ", 
        "                kernel = \"polynomial\", degree = ___,", 
        "                cost = c,", "                gamma = gma)", 
        "", "# ¿Cuántas de las observaciones son vectores soporte?", 
        "length(svm_model_p$index) "), out.width.px = 624, out.height.px = 384, 
        params.src = "ej8, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ej9-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ej9-code-editor`)), session)
output$`tutorial-exercise-ej9-output` <- renderUI({
  `tutorial-exercise-ej9-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ej9", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "ej9", code = "pred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nsvm_p_plot <- plot(svm_model_p, trainset)", 
        opts = list(label = "\"ej9\"", exercise = "TRUE", exercise.setup = "\"datas\""), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, options = list(eval = FALSE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        strip.white = TRUE, size = "normalsize", background = "#F7F7F7", 
        cache = 0, cache.path = "Tutorial_SVM_cache/html/", cache.vars = NULL, 
        cache.lazy = TRUE, dependson = NULL, autodep = FALSE, 
        cache.rebuild = FALSE, fig.keep = "high", fig.show = "asis", 
        fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ej9", exercise = TRUE, 
        exercise.setup = "datas", code = c("pred_test_p <- predict(svm_model_p, testset)", 
        "mean(pred_test_p == testset$gender) #accuracy", "", 
        "svm_p_plot <- plot(svm_model_p, trainset)"), out.width.px = 624, 
        out.height.px = 384, params.src = "ej9, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-ej10-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-ej10-code-editor`)), session)
output$`tutorial-exercise-ej10-output` <- renderUI({
  `tutorial-exercise-ej10-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache("ej10", list(setup = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
    chunks = list(list(label = "datas", code = "set.seed(1)\n# Este es prácticamente todo lo que desarrollaremos en el tutorial, de aquí \n# tomaremos los objetos.\n\n# Cargar datos y \"limpiarlos\"\ninfo <- read.csv(\"https://raw.githubusercontent.com/CarlosA-Ar/SVM-con-R/main/csvs/speed_gender_height.csv\")\ninfo <- info[, -1]\ninfo$gender <- as.factor(info$gender)\ninfo <- na.omit(info)\n\n# Graficar los datos\nplot_info <- ggplot(info, aes(x = speed, y = height, color = gender)) + geom_point() + ggtitle(\"Personal Information\")+ theme_minimal() + scale_color_manual(values = c(\"#BD9B17\", \"#1A1458\"))\n\n# Separar datos\n# 80% para construir el modelo, 20% para \"probar su capacidad de predecir\"\ninfo[, \"train\"] <- ifelse(runif(nrow(info)) < .8, 1, 0)\ntrainset <- info[info$train == 1, ]\ntestset <- info[info$train == 0, ]\n\ntrainColNum <- grep(\"train\", names(info))\ntrainset <- trainset[, -trainColNum]\ntestset <- testset[, -trainColNum]\n\n# Construir modelos (ver lo que se obtiene + una gráfica y un accuracy)\n\n## Lineal\nsvm_model_l <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"linear\", \n                scale = FALSE)\nnames(svm_model_l) # ¿Qué nos devuelve el modelo?\nsvm_model_l$index # ¿Cuáles observaciones son vectores soporte?\nsvm_model_l$rho # Beta0 (intercepto)\n\npred_test_1 <- predict(svm_model_l, testset)\nmean(pred_test_1 == testset$gender) #accuracy\n\nw <- t(svm_model_l$coefs) %*% svm_model_l$SV\nslope_l <- -w[1]/w[2]\nintercerpt_l <- svm_model_l$rho / w[2]\nplot_info_svm_l <-  plot_info + \n  geom_point(data = trainset[svm_model_l$index,],\n             aes(x = speed, y = height),\n             color = \"#6EA815\", size = 2, alpha = .3) +\n  geom_abline(slope = slope_l,\n              intercept = intercerpt_l,\n              size = 1,\n              color = \"#A91323\") + \n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l - 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\") +\n  geom_abline(slope = slope_l, \n              intercept = intercerpt_l + 1/w[2],\n              linetype = \"dashed\",\n              color = \"#A91323\")\nplot(svm_model_l, trainset)\n\n## Polinomial: con la función tune\ntune_out_p <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"polynomial\", degree = 2,\n    cost = 10^(-1:1),\n    gamma = c(0.1, 1)\n    )\nc <- tune_out_p$best.parameters$cost\ngma <- tune_out_p$best.parameters$gamma\n\nsvm_model_p <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"polynomial\", degree = 2,\n                cost = c,\n                gamma = gma)\nlength(svm_model_p$index) # ¿Cuáles observaciones son vectores soporte?\n\npred_test_p <- predict(svm_model_p, testset)\nmean(pred_test_p == testset$gender) #accuracy\n\nplot(svm_model_p, trainset)\n\n## Radial: con la función tune.\ntune_out_r <- \n  tune.svm(\n    x = trainset[, -2], y = trainset[, 2],\n    type = \"C-classification\",\n    kernel = \"radial\",\n    gamma = 10^(-1:2),\n    cost = c(0.01, 0.1, 1, 10)\n    )\nsvm_model_r <- svm(gender ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"radial\",\n                cost = tune_out_r$best.parameters$cost,\n                gamma = tune_out_r$best.parameters$gamma)\n#svm_model_r1 <- svm(gender ~ ., \n#                data = trainset, \n#                type = \"C-classification\", \n#                kernel = \"radial\")\n#mean(pred_test_r <- predict(svm_model_r1, testset) == testset$gender)\n\nsummary(svm_model_r) \n\npred_test_r <- predict(svm_model_r, testset)\nmean(pred_test_r == testset$gender) #accuracy\n\nplot(svm_model_r, trainset)", 
        opts = list(label = "\"datas\""), engine = "r"), list(
        label = "ej10", code = "svm_model_r <- svm(____ ~ ., \n                data = trainset, \n                type = \"C-classification\", \n                kernel = \"____\",\n                cost = tune_out_r$best.parameters$___,\n                gamma = tune_out_r$____$gamma)\n\nsummary(____) \n\npred_test_r <- predict(svm_model_r, ____)\nmean(_____ == testset$gender) #accuracy\n\nplot(svm_model_r, _____)", 
        opts = list(label = "\"ej10\"", exercise = "TRUE", exercise.setup = "\"datas\""), 
        engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = structure(c("svm_model_r <- svm(gender ~ ., ", 
    "                data = trainset, ", "                type = \"C-classification\", ", 
    "                kernel = \"radial\",", "                cost = tune_out_r$best.parameters$cost,", 
    "                gamma = tune_out_r$best.parameters$gamma)", 
    "", "summary(svm_model_r) ", "", "pred_test_r <- predict(svm_model_r, testset)", 
    "mean(pred_test_r == testset$gender) #accuracy", "", "plot(svm_model_r, trainset)"
    ), chunk_opts = list(label = "ej10-solution")), options = list(
        eval = FALSE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, strip.white = TRUE, size = "normalsize", 
        background = "#F7F7F7", cache = 0, cache.path = "Tutorial_SVM_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "center", fig.path = "Tutorial_SVM_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 6.5, fig.height = 4, fig.env = "figure", 
        fig.cap = NULL, fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 624, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = TRUE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, tutorial = TRUE, label = "ej10", exercise = TRUE, 
        exercise.setup = "datas", code = c("svm_model_r <- svm(____ ~ ., ", 
        "                data = trainset, ", "                type = \"C-classification\", ", 
        "                kernel = \"____\",", "                cost = tune_out_r$best.parameters$___,", 
        "                gamma = tune_out_r$____$gamma)", "", 
        "summary(____) ", "", "pred_test_r <- predict(svm_model_r, ____)", 
        "mean(_____ == testset$gender) #accuracy", "", "plot(svm_model_r, _____)"
        ), out.width.px = 624, out.height.px = 384, params.src = "ej10, exercise = TRUE, exercise.setup = \"datas\"", 
        fig.num = 0, exercise.df_print = "paged", exercise.checker = "NULL"), 
    engine = "r"))
</script>
 <!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.9"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.9"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.9"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.9"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.9"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.9"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1.9009"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1.9009"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1.9009"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["i18n"]},{"type":"character","attributes":{},"value":["1.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/i18n"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["i18next.min.js","tutorial-i18n-init.js"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["<script id=\"i18n-cstm-trns\" type=\"application/json\">{\"language\":\"en\",\"resources\":{\"en\":{\"translation\":{\"button\":{\"runcode\":\"Run Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Hint\",\"hint_plural\":\"Hints\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Next Hint\",\"hintprev\":\"Previous Hint\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copy to Clipboard\",\"startover\":\"Start Over\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continue\",\"submitanswer\":\"Submit Answer\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Previous Topic\",\"nexttopic\":\"Next Topic\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Try Again\"},\"text\":{\"startover\":\"Start Over\",\"areyousure\":\"Are you sure you want to start over? (all exercise progress will be reset)\",\"youmustcomplete\":\"You must complete the\",\"exercise\":\"exercise\",\"exercise_plural\":\"exercises\",\"inthissection\":\"in this section before continuing.\",\"code\":\"Code\",\"enginecap\":\"{{engine}} $t(text.code)\",\"quiz\":\"Quiz\"}}},\"fr\":{\"translation\":{\"button\":{\"runcode\":\"Lancer le Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Indication\",\"hint_plural\":\"Indications\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Indication Suivante\",\"hintprev\":\"Indication Précédente\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copier dans le Presse-papier\",\"startover\":\"Recommencer\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuer\",\"submitanswer\":\"Soumettre\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Chapitre Précédent\",\"nexttopic\":\"Chapitre Suivant\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Réessayer\"},\"text\":{\"startover\":\"Recommencer\",\"areyousure\":\"Êtes-vous certains de vouloir recommencer? (La progression sera remise à zéro)\",\"youmustcomplete\":\"Vous devez d'abord compléter\",\"exercise\":\"l'exercice\",\"exercise_plural\":\"des exercices\",\"inthissection\":\"de cette section avec de continuer.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\"}}},\"es\":{\"translation\":{\"button\":{\"runcode\":\"Ejecutar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Pista\",\"hint_plural\":\"Pistas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Siguiente pista\",\"hintprev\":\"Pista anterior\",\"solution\":\"Solución\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar al portapapeles\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar respuesta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tema anterior\",\"nexttopic\":\"Tema siguiente\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Volver a intentar\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"¿De verdad quieres empezar de nuevo? (todo el progreso del ejercicio se perderá)\",\"youmustcomplete\":\"Debes completar\",\"exercise\":\"el ejercicio\",\"exercise_plural\":\"los ejercicios\",\"inthissection\":\"en esta sección antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Cuestionario\"}}},\"pt\":{\"translation\":{\"button\":{\"runcode\":\"Executar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Dica\",\"hint_plural\":\"Dicas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Próxima dica\",\"hintprev\":\"Dica anterior\",\"solution\":\"Solução\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar para a área de transferência\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar resposta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tópico anterior\",\"nexttopic\":\"Próximo tópico\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tentar novamente\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"Tem certeza que deseja começar novamente? (todo o progresso feito será perdido)\",\"youmustcomplete\":\"Você deve completar\",\"exercise\":\"o exercício\",\"exercise_plural\":\"os exercícios\",\"inthissection\":\"nesta seção antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\"}}},\"tr\":{\"translation\":{\"button\":{\"runcode\":\"Çalistirma Kodu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Ipucu\",\"hint_plural\":\"Ipuçlari\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Sonraki Ipucu\",\"hintprev\":\"Önceki Ipucu\",\"solution\":\"Çözüm\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Pano'ya Kopyala\",\"startover\":\"Bastan Baslamak\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Devam et\",\"submitanswer\":\"Cevabi onayla\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Önceki Konu\",\"nexttopic\":\"Sonraki Konu\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tekrar Deneyin\"},\"text\":{\"startover\":\"Bastan Baslamak\",\"areyousure\":\"Bastan baslamak istediginizden emin misiniz? (tüm egzersiz ilerlemesi kaybolacak)\",\"youmustcomplete\":\"Tamamlamalisin\",\"exercise\":\"egzersiz\",\"exercise_plural\":\"egzersizler\",\"inthissection\":\"devam etmeden önce bu bölümde\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Sinav\"}}},\"emo\":{\"translation\":{\"button\":{\"runcode\":\"<U+0001F3C3>\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"<U+0001F4A1>\",\"hint_plural\":\"$t(button.hint)\",\"hinttitle\":\"$t(button.hint)\",\"solution\":\"<U+0001F3AF>\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"<U+0001F4CB>\",\"startover\":\"<U+23EE>\",\"startovertitle\":\"Start Over\",\"continue\":\"<U+2705>\",\"submitanswer\":\"<U+0001F197>\",\"submitanswertitle\":\"Submit Answer\",\"previoustopic\":\"<U+2B05>\",\"nexttopic\":\"<U+27A1>\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"<U+0001F501>\"},\"text\":{\"startover\":\"<U+23EE>\",\"areyousure\":\"<U+0001F914>\",\"youmustcomplete\":\"<U+26A0><U+FE0F> <U+0001F449> <U+0001F9D1><U+200D><U+0001F4BB>\",\"exercise\":\"\",\"exercise_plural\":\"\",\"inthissection\":\"\",\"code\":\"<U+0001F4BB>\",\"enginecap\":\"$t(text.code) {{engine}}\"}}},\"eu\":{\"translation\":{\"button\":{\"runcode\":\"Kodea egikaritu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Laguntza\",\"hint_plural\":\"Laguntza\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Aurreko laguntza\",\"hintprev\":\"Hurrengo laguntza\",\"solution\":\"Ebazpena\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Arbelean kopiatu\",\"startover\":\"Berrabiarazi\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Jarraitu\",\"submitanswer\":\"Erantzuna bidali\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Aurreko atala\",\"nexttopic\":\"Hurrengo atala\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Berriro saiatu\"},\"text\":{\"startover\":\"Berrabiarazi\",\"areyousure\":\"Berriro hasi nahi duzu? (egindako lana galdu egingo da)\",\"youmustcomplete\":\"Aurrera egin baino lehen atal honetako\",\"exercise\":\"ariketa egin behar duzu.\",\"exercise_plural\":\"ariketak egin behar dituzu.\",\"inthissection\":\"\",\"code\":\"Kodea\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Galdetegia\"}}}}}<\/script>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.10.1.9009"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.9"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.9"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.9"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.9"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.9"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1.9009"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1.9009"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1.9009"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1.9009"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69]}},"value":[{"type":"character","attributes":{},"value":["assertthat","backports","base","bslib","cellranger","checkmate","class","colorspace","compiler","crayon","curl","datasets","DBI","digest","dplyr","e1071","ellipsis","evaluate","fansi","fastmap","generics","ggplot2","glue","graphics","grDevices","grid","gridExtra","gtable","htmltools","htmlwidgets","httpuv","jquerylib","jsonlite","knitr","later","learnr","lifecycle","magrittr","markdown","methods","mime","munsell","pillar","pkgconfig","promises","proxy","purrr","R6","Rcpp","readxl","rlang","rmarkdown","rprojroot","sass","scales","shiny","stats","stringi","stringr","tibble","tidyselect","tools","utf8","utils","vctrs","withr","xfun","xtable","yaml"]},{"type":"character","attributes":{},"value":["0.2.1","1.2.1","4.1.0","0.2.5.1","1.1.0","2.0.0","7.3-19","2.0-1","4.1.0","1.4.1","4.3.1","4.1.0","1.1.1","0.6.27","1.0.6","1.7-8","0.3.2","0.14","0.5.0","1.1.0","0.1.0","3.3.3","1.4.2","4.1.0","4.1.0","4.1.0","2.3","0.3.0","0.5.1.1","1.5.3","1.6.1","0.1.4","1.7.2","1.33","1.2.0","0.10.1.9009","1.0.0","2.0.1","1.1","4.1.0","0.11","0.5.0","1.6.1","2.0.3","1.2.0.1","0.4-26","0.3.4","2.5.0","1.0.6","1.3.1","0.4.11","2.9","2.0.2","0.4.0","1.1.1","1.6.0","4.1.0","1.6.2","1.4.0","3.1.2","1.1.1","4.1.0","1.2.1","4.1.0","0.3.8","2.4.2","0.23","1.8-4","2.2.1"]}]}]}
</script>
<!--/html_preserve-->
</div>
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">Support Vector Machines in R</h2>
<h4 class="author"><em>Carlos A. Ar.</em></h4>
<h4 class="author"><em>Ciencia de Datos</em></h4>
<h4 class="author"><em>Facultad de Ciencias</em></h4>
<h4 class="author"><em>UNAM</em></h4>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->



<!-- Build Tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
